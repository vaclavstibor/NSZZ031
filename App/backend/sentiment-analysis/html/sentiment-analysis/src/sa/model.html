<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.0">
<title>sentiment-analysis.src.sa.model API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sentiment-analysis.src.sa.model</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sentiment-analysis.src.sa.model.analyse_sentiment"><code class="name flex">
<span>async def <span class="ident">analyse_sentiment</span></span>(<span>model: sentiment-analysis.src.sa.model.Model, content: str, entities: List[src.models.entity.Entity]) ‑> List[src.models.ticker_with_sentiment.TickerWithSentiment]</span>
</code></dt>
<dd>
<div class="desc"><p>Asynchronously analyse the sentiment of the content. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code><a title="sentiment-analysis.src.sa.model.Model" href="#sentiment-analysis.src.sa.model.Model">Model</a></code></dt>
<dd>The sentiment analysis model.</dd>
<dt><strong><code>content</code></strong> :&ensp;<code>str</code></dt>
<dd>The content to analyse.</dd>
<dt><strong><code>entities</code></strong> :&ensp;<code>List[Entity]</code></dt>
<dd>The entities to analyse.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[TickerWithSentiment]</code></dt>
<dd>The list of tickers with sentiment scores.</dd>
</dl></div>
</dd>
<dt id="sentiment-analysis.src.sa.model.convert_to_tickers_with_sentiment"><code class="name flex">
<span>def <span class="ident">convert_to_tickers_with_sentiment</span></span>(<span>entities_with_sentiment: List[src.models.entity_with_sentiment.EntityWithSentiment]) ‑> List[src.models.ticker_with_sentiment.TickerWithSentiment]</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a list of entities with sentiment scores to a list of tickers with sentiment scores.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>entities_with_sentiment</code></strong> :&ensp;<code>List[EntityWithSentiment]</code></dt>
<dd>The list of entities with sentiment scores.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[TickerWithSentiment]</code></dt>
<dd>The list of tickers with sentiment scores.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sentiment-analysis.src.sa.model.Model"><code class="flex name class">
<span>class <span class="ident">Model</span></span>
<span>(</span><span>ckpt_path='amphora/FinABSA-Longer', max_length=512)</span>
</code></dt>
<dd>
<div class="desc"><p>Model class for sentiment analysis.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>ckpt_path</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the checkpoint.</dd>
<dt><strong><code>max_length</code></strong> :&ensp;<code>int</code></dt>
<dd>The maximum length of the input.</dd>
<dt><strong><code>device</code></strong> :&ensp;<code>torch.device</code></dt>
<dd>The device used for inference.</dd>
<dt><strong><code>ABSA</code></strong> :&ensp;<code>AutoModelForSeq2SeqLM</code></dt>
<dd>The ABSA model.</dd>
<dt><strong><code>tokenizer</code></strong> :&ensp;<code>AutoTokenizer</code></dt>
<dd>The tokenizer.</dd>
<dt><strong><code>executor</code></strong> :&ensp;<code>ThreadPoolExecutor</code></dt>
<dd>The executor for running blocking functions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Model:
    &#34;&#34;&#34;
    Model class for sentiment analysis.

    Attributes:
        ckpt_path (str): The path to the checkpoint.
        max_length (int): The maximum length of the input.
        device (torch.device): The device used for inference.
        ABSA (AutoModelForSeq2SeqLM): The ABSA model.
        tokenizer (AutoTokenizer): The tokenizer.
        executor (ThreadPoolExecutor): The executor for running blocking functions.
    &#34;&#34;&#34;
    
    def __init__(self, ckpt_path=&#34;amphora/FinABSA-Longer&#34;, max_length=512):
        self.device = torch.device(&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;)
        logging.info(f&#34;Using device: {self.device}&#34;)

        self.ABSA = AutoModelForSeq2SeqLM.from_pretrained(ckpt_path).to(self.device)
        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_path)
        self.max_length = max_length
        self.executor = ThreadPoolExecutor()

    async def run_absa(self, input_str: str, input_entities: List[Entity]) -&gt; List[EntityWithSentiment]:
        &#34;&#34;&#34;
        Run sentiment analysis on the input string. The input string is split into chunks
        and sentiment analysis is run on each chunk. The sentiment scores are then averaged
        to get the final sentiment scores for each entity.

        Args:
            input_str (str): The input string.
            input_entities (List[Entity]): The list of entities.

        Returns:
            List[EntityWithSentiment]: The list of entities with sentiment scores.
        &#34;&#34;&#34;
        
        chunks = self.split_into_chunks(input_str)
        entity_text_scores_dict = {
            entity.text: {
                &#34;positive&#34;: 0.0,
                &#34;negative&#34;: 0.0,
                &#34;neutral&#34;: 0.0,
                &#34;count&#34;: 0,
                &#34;classification&#34;: &#34;NEUTRAL&#34;,
            }
            for entity in input_entities
        }

        futures = []
        for chunk in chunks:
            tgt_entities = self.retrieve_target(chunk, input_entities)
            for e in tgt_entities:
                futures.append(asyncio.create_task(self.run_single_absa(chunk, e.text)))

        # Run sentiment analysis on each chunk
        results = await asyncio.gather(*futures)
        for chunk_result in results:
            e_text = chunk_result[&#34;entity&#34;]
            scores = entity_text_scores_dict[e_text]
            scores[&#34;positive&#34;] += chunk_result[&#34;logits&#34;][&#34;positive&#34;]
            scores[&#34;negative&#34;] += chunk_result[&#34;logits&#34;][&#34;negative&#34;]
            scores[&#34;neutral&#34;] += chunk_result[&#34;logits&#34;][&#34;neutral&#34;]
            scores[&#34;count&#34;] += 1

        entities_with_sentiment = []
        for entity_text, scores in entity_text_scores_dict.items():
            if scores[&#34;count&#34;] &gt; 0:
                scores[&#34;positive&#34;] /= scores[&#34;count&#34;]
                scores[&#34;negative&#34;] /= scores[&#34;count&#34;]
                scores[&#34;neutral&#34;] /= scores[&#34;count&#34;]
                max_score = max(scores[&#34;positive&#34;], scores[&#34;negative&#34;], scores[&#34;neutral&#34;])
                if max_score == scores[&#34;positive&#34;]:
                    scores[&#34;classification&#34;] = &#34;POSITIVE&#34;
                elif max_score == scores[&#34;negative&#34;]:
                    scores[&#34;classification&#34;] = &#34;NEGATIVE&#34;
                else:
                    scores[&#34;classification&#34;] = &#34;NEUTRAL&#34;

                sentiment = Sentiment(
                    classification=scores[&#34;classification&#34;],
                    positive=scores[&#34;positive&#34;],
                    negative=scores[&#34;negative&#34;],
                    neutral=scores[&#34;neutral&#34;],
                )

                entities_with_sentiment.append(
                    EntityWithSentiment(
                        text=entity_text,
                        ticker=[entity.ticker for entity in input_entities if entity.text == entity_text][0],
                        sentiment=sentiment,
                    )
                )

        logging.log(logging.INFO, f&#34;entities_with_sentiment: {entities_with_sentiment}&#34;)
        return entities_with_sentiment
    
    async def run_single_absa(self, chunk: str, tgt: str) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Run sentiment analysis on a single chunk.

        Args:
            chunk (str): The input chunk.
            tgt (str): The target entity.

        Returns:
            Dict[str, Any]: The sentiment scores for the target entity.
        &#34;&#34;&#34;
        
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(self.executor, self._blocking_single_absa, chunk, tgt)

    def _blocking_single_absa(self, chunk: str, tgt: str) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Blocking function to run sentiment analysis on a single chunk. 
        
        Args:
            chunk (str): The input chunk.
            tgt (str): The target entity.

        Returns:
            Dict[str, Any]: The sentiment scores for the target entity.
        &#34;&#34;&#34;
        
        chunk = chunk.replace(tgt, &#34;[TGT]&#34;)
        input = self.tokenizer(chunk, return_tensors=&#34;pt&#34;).to(self.device)
        output = self.ABSA.generate(
            **input, max_length=20, output_scores=True, return_dict_in_generate=True
        )
        logits = F.softmax(output[&#34;scores&#34;][-4][:, -3:], dim=1)[0]
        return {
            &#34;entity&#34;: tgt,
            &#34;logits&#34;: {
                &#34;positive&#34;: float(logits[0]),
                &#34;negative&#34;: float(logits[1]),
                &#34;neutral&#34;: float(logits[2]),
            },
        }

    def retrieve_target(self, input_str, input_entities: List[Entity]) -&gt; List[Entity]:
        &#34;&#34;&#34;
        Retrieve the target entities from the input string. 

        Args:
            input_str (str): The input string.
            input_entities (List[Entity]): The list of entities.
        
        Returns:
            List[Entity]: The target entities.
        &#34;&#34;&#34;
        
        entities = [entity for entity in input_entities if entity.text in input_str]
        logging.info(&#34;(retrieve_target) ENTITIES: %s %s&#34;, len(entities), entities)
        return entities

    def split_into_chunks(self, input_str: str) -&gt; List[str]:
        &#34;&#34;&#34;
        Split the input string into chunks. 

        Args:
            input_str (str): The input string.

        Returens:
            List[str]: The list of chunks.
        &#34;&#34;&#34;
        
        sentences = sent_tokenize(input_str)
        chunks = []
        current_chunk = &#34;&#34;
        current_tokens_count = 0
        for sentence in sentences:
            sentence_tokens = self.tokenizer(sentence).word_ids()
            sentence_tokens_count = len(sentence_tokens)
            if current_tokens_count + sentence_tokens_count &lt;= self.max_length:
                current_chunk += sentence
                current_tokens_count += sentence_tokens_count
            else:
                chunks.append(current_chunk)
                current_chunk = sentence
                current_tokens_count = sentence_tokens_count
        if current_chunk:
            chunks.append(current_chunk)
        return chunks</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="sentiment-analysis.src.sa.model.Model.retrieve_target"><code class="name flex">
<span>def <span class="ident">retrieve_target</span></span>(<span>self, input_str, input_entities: List[src.models.entity.Entity]) ‑> List[src.models.entity.Entity]</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve the target entities from the input string. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_str</code></strong> :&ensp;<code>str</code></dt>
<dd>The input string.</dd>
<dt><strong><code>input_entities</code></strong> :&ensp;<code>List[Entity]</code></dt>
<dd>The list of entities.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Entity]</code></dt>
<dd>The target entities.</dd>
</dl></div>
</dd>
<dt id="sentiment-analysis.src.sa.model.Model.run_absa"><code class="name flex">
<span>async def <span class="ident">run_absa</span></span>(<span>self, input_str: str, input_entities: List[src.models.entity.Entity]) ‑> List[src.models.entity_with_sentiment.EntityWithSentiment]</span>
</code></dt>
<dd>
<div class="desc"><p>Run sentiment analysis on the input string. The input string is split into chunks
and sentiment analysis is run on each chunk. The sentiment scores are then averaged
to get the final sentiment scores for each entity.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_str</code></strong> :&ensp;<code>str</code></dt>
<dd>The input string.</dd>
<dt><strong><code>input_entities</code></strong> :&ensp;<code>List[Entity]</code></dt>
<dd>The list of entities.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[EntityWithSentiment]</code></dt>
<dd>The list of entities with sentiment scores.</dd>
</dl></div>
</dd>
<dt id="sentiment-analysis.src.sa.model.Model.run_single_absa"><code class="name flex">
<span>async def <span class="ident">run_single_absa</span></span>(<span>self, chunk: str, tgt: str) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Run sentiment analysis on a single chunk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>chunk</code></strong> :&ensp;<code>str</code></dt>
<dd>The input chunk.</dd>
<dt><strong><code>tgt</code></strong> :&ensp;<code>str</code></dt>
<dd>The target entity.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Any]</code></dt>
<dd>The sentiment scores for the target entity.</dd>
</dl></div>
</dd>
<dt id="sentiment-analysis.src.sa.model.Model.split_into_chunks"><code class="name flex">
<span>def <span class="ident">split_into_chunks</span></span>(<span>self, input_str: str) ‑> List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Split the input string into chunks. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_str</code></strong> :&ensp;<code>str</code></dt>
<dd>The input string.</dd>
</dl>
<h2 id="returens">Returens</h2>
<p>List[str]: The list of chunks.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sentiment-analysis.src.sa" href="index.html">sentiment-analysis.src.sa</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sentiment-analysis.src.sa.model.analyse_sentiment" href="#sentiment-analysis.src.sa.model.analyse_sentiment">analyse_sentiment</a></code></li>
<li><code><a title="sentiment-analysis.src.sa.model.convert_to_tickers_with_sentiment" href="#sentiment-analysis.src.sa.model.convert_to_tickers_with_sentiment">convert_to_tickers_with_sentiment</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sentiment-analysis.src.sa.model.Model" href="#sentiment-analysis.src.sa.model.Model">Model</a></code></h4>
<ul class="">
<li><code><a title="sentiment-analysis.src.sa.model.Model.retrieve_target" href="#sentiment-analysis.src.sa.model.Model.retrieve_target">retrieve_target</a></code></li>
<li><code><a title="sentiment-analysis.src.sa.model.Model.run_absa" href="#sentiment-analysis.src.sa.model.Model.run_absa">run_absa</a></code></li>
<li><code><a title="sentiment-analysis.src.sa.model.Model.run_single_absa" href="#sentiment-analysis.src.sa.model.Model.run_single_absa">run_single_absa</a></code></li>
<li><code><a title="sentiment-analysis.src.sa.model.Model.split_into_chunks" href="#sentiment-analysis.src.sa.model.Model.split_into_chunks">split_into_chunks</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.0</a>.</p>
</footer>
</body>
</html>
