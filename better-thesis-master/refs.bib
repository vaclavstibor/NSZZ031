% In biblatex, there are several citation commands you can use, each providing a different format. Here are some of the most commonly used ones:
% \cite: This is the basic citation command. It prints the author and year for authoryear style, or the numeric label for numeric style.
% \parencite: This command wraps the citation in parentheses. It's equivalent to \cite in numeric style.
% \footcite: This command puts the citation in a footnote.
% \textcite: This command is designed for in-text citations. It prints the author's name as part of the sentence and the year in parentheses.
% \citeauthor: This command prints the author's name(s) only.
% \citetitle: This command prints the title of the cited work only.
% \citeyear: This command prints the year of the cited work only.
% \fullcite: This command prints a full bibliography entry in the text.

@phdthesis{saunders_2020,
  title={Domain adaptation for neural machine translation},
  url={https://www.repository.cam.ac.uk/handle/1810/319335},
  DOI={10.17863/CAM.66458}, 
  school={Apollo - University of Cambridge Repository}, 
  author={Saunders, Danielle}, 
  year={2020}, 
  keywords={Neural machine translation, Natural language processing, Domain adaptation}
}

@article{PIRYANI2017122,
title = {Analytical mapping of opinion mining and sentiment analysis research during 2000–2015},
journal = {Information Processing \& Management},
volume = {53},
number = {1},
pages = {122-150},
year = {2017},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2016.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S030645731630245X},
author = {R. Piryani and D. Madhavi and V.K. Singh},
keywords = {Affective computing, Opinion mining, Scientometrics, Sentiment analysis},
abstract = {The new transformed read-write Web has resulted in a rapid growth of user generated content on the Web resulting into a huge volume of unstructured data. A substantial part of this data is unstructured text such as reviews and blogs. Opinion mining and sentiment analysis (OMSA) as a research discipline has emerged during last 15 years and provides a methodology to computationally process the unstructured data mainly to extract opinions and identify their sentiments. The relatively new but fast growing research discipline has changed a lot during these years. This paper presents a scientometric analysis of research work done on OMSA during 2000–2016. For the scientometric mapping, research publications indexed in Web of Science (WoS) database are used as input data. The publication data is analyzed computationally to identify year-wise publication pattern, rate of growth of publications, types of authorship of papers on OMSA, collaboration patterns in publications on OMSA, most productive countries, institutions, journals and authors, citation patterns and an year-wise citation reference network, and theme density plots and keyword bursts in OMSA publications during the period. A somewhat detailed manual analysis of the data is also performed to identify popular approaches (machine learning and lexicon-based) used in these publications, levels (document, sentence or aspect-level) of sentiment analysis work done and major application areas of OMSA. The paper presents a detailed analytical mapping of OMSA research work and charts the progress of discipline on various useful parameters.}
}

@article{Wankhade2022,
author={Wankhade, Mayur
and Rao, Annavarapu Chandra Sekhara
and Kulkarni, Chaitanya},
title={A survey on sentiment analysis methods, applications, and challenges},
journal={Artificial Intelligence Review},
year={2022},
month={8},
day={01},
volume={55},
number={7},
pages={5731-5780},
abstract={The rapid growth of Internet-based applications, such as social media platforms and blogs, has resulted in comments and reviews concerning day-to-day activities. Sentiment analysis is the process of gathering and analyzing people's opinions, thoughts, and impressions regarding various topics, products, subjects, and services. People's opinions can be beneficial to corporations, governments, and individuals for collecting information and making decisions based on opinion. However, the sentiment analysis and evaluation procedure face numerous challenges. These challenges create impediments to accurately interpreting sentiments and determining the appropriate sentiment polarity. Sentiment analysis identifies and extracts subjective information from the text using natural language processing and text mining. This article discusses a complete overview of the method for completing this task as well as the applications of sentiment analysis. Then, it evaluates, compares, and investigates the approaches used to gain a comprehensive understanding of their advantages and disadvantages. Finally, the challenges of sentiment analysis are examined in order to define future directions.},
issn={1573-7462},
doi={10.1007/s10462-022-10144-1},
url={https://doi.org/10.1007/s10462-022-10144-1}
}

@article{Jenifer2017,
  title={Jen-Ton: A framework to enhance the accuracy of aspect level sentiment analysis in big data},
  author={A. Jenifer Jothi Mary and Lawrence Arockiam},
  journal={2017 International Conference on Inventive Computing and Informatics (ICICI)},
  year={2017},
  pages={452-457},
  url={https://api.semanticscholar.org/CorpusID:44112128}
}

@inproceedings{Wang2019,
author = {Wang, Yequan and Sun, Aixin and Huang, Minlie and Zhu, Xiaoyan},
title = {Aspect-level Sentiment Analysis using AS-Capsules},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313750},
doi = {10.1145/3308558.3313750},
abstract = {Aspect-level sentiment analysis aims to provide complete and detailed view of sentiment analysis from different aspects. Existing solutions usually adopt a two-staged approach: first detecting aspect category in a document, then categorizing the polarity of opinion expressions for detected aspect(s). Inevitably, such methods lead to error accumulation. Moreover, aspect detection and aspect-level sentiment classification are highly correlated with each other. The key issue here is how to perform aspect detection and aspect-level sentiment classification jointly, and effectively. In this paper, we propose the aspect-level sentiment capsules model (AS-Capsules), which is capable of performing aspect detection and sentiment classification simultaneously, in a joint manner. AS-Capsules utilizes the correlation between aspect and sentiment through shared components including capsule embedding, shared encoders, and shared attentions. AS-Capsules is also capable of communicating with different capsules through a shared Recurrent Neural Network (RNN). More importantly, AS-Capsules model does not require any linguistic knowledge as additional input. Instead, through the attention mechanism, this model is able to attend aspect related words and sentiment words corresponding to different aspect(s). Experiments show that the AS-Capsules model achieves state-of-the-art performances on a benchmark dataset for aspect-level sentiment analysis.},
booktitle = {The World Wide Web Conference},
pages = {2033–2044},
numpages = {12},
series = {WWW '19}
}

@inbook{Liu2015, 
place={Cambridge}, 
title={Aspect and Entity Extraction}, 
booktitle={Sentiment Analysis: Mining Opinions, Sentiments, and Emotions}, 
publisher={Cambridge University Press}, 
author={Liu, Bing}, 
year={2015}, 
pages={137–188}
}

@Inbook{Zhang2014,
author="Zhang, Lei
and Liu, Bing",
editor="Chu, Wesley W.",
title="Aspect and Entity Extraction for Opinion Mining",
bookTitle="Data Mining and Knowledge Discovery for Big Data: Methodologies, Challenge and Opportunities",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--40",
abstract="Opinion mining or sentiment analysis is the computational study of people's opinions, appraisals, attitudes, and emotions toward entities such as products, services, organizations, individuals, events, and their different aspects. It has been an active research area in natural language processing and Web mining in recent years. Researchers have studied opinion mining at the document, sentence and aspect levels. Aspect-level (called aspect-based opinion mining) is often desired in practical applications as it provides the detailed opinions or sentiments about different aspects of entities and entities themselves, which are usually required for action. Aspect extraction and entity extraction are thus two core tasks of aspect-based opinion mining. In this chapter, we provide a broad overview of the tasks and the current state-of-the-art extraction techniques.",
isbn="978-3-642-40837-3",
doi="10.1007/978-3-642-40837-3_1",
url="https://doi.org/10.1007/978-3-642-40837-3_1"
}

@inbook{liu2022sentiment,
  title={Sentiment analysis and opinion mining},
  author={Liu, Bing},
  year={2022},
  publisher={Springer Nature},
  chapter={3},
  pages={31--36}
}

% údajně je white paper technický paper
@online{bloomberg,
  title={Embedded Value in Bloomberg News \& Social Sentiment Data},
  author={Xin Cui and Daniel Lam and Arun Verma and Bloomberg L.P.},
  year={2024},
  note={Received via email from Bloomberg L.P. on 2.2.2024},
  url={https://data.bloomberglp.com/promo/sites/12/725454457_EDFSentimentWP.pdf},
  urldate={2024-02-02},
}

@online{TheGuardiaArticleDeepFake,
  title={UK's enemies could use AI deepfakes to try to rig election, says James Cleverly},
  author={The Guardian},
  year={2024},
  note={Article discussing the potential use of AI-generated deepfakes in elections, featuring statements from James Cleverly, the UK's Home Secretary.},
  url={https://www.theguardian.com/uk-news/2024/feb/25/uks-enemies-could-use-ai-deepfakes-to-try-to-rig-election-says-james-cleverly},
  urldate={2024-04-22}
}

@article{chenInformationalRole,
title = {Informational role of social media: Evidence from Twitter sentiment},
journal = {Journal of Banking \& Finance},
volume = {121},
pages = {105969},
year = {2020},
issn = {0378-4266},
doi = {https://doi.org/10.1016/j.jbankfin.2020.105969},
url = {https://www.sciencedirect.com/science/article/pii/S0378426620302314},
author = {Chen Gu and Alexander Kurov},
keywords = {Twitter sentiment, News sentiment, Social media, Return predictability, Analyst recommendations, Earnings forecasts, Target prices},
abstract = {This paper examines the information content of firm-specific sentiment extracted from Twitter messages. We find that Twitter sentiment predicts stock returns without subsequent reversals. This finding is consistent with the view that tweets provide information not already reflected in stock prices. We investigate possible sources of return predictability with Twitter sentiment. The results show that Twitter sentiment provides new information about analyst recommendations, analyst price targets and quarterly earnings. This information explains about one third of the predictive ability of Twitter sentiment for stock returns. Taken together, our findings shed new light on whether and why social media content has predictive value for stock returns.}
}

@article{Jin2012,
author={Jin, Yingzi
and Lin, Ching-Yung
and Matsuo, Yutaka
and Ishizuka, Mitsuru},
title={Mining dynamic social networks from public news articles for company value prediction},
journal={Social Network Analysis and Mining},
year={2012},
month={Sep},
day={01},
volume={2},
number={3},
pages={217-228},
abstract={Dynamic networks are studied by sociologists to understand network evolution, belief formation, friendship formation, etc. Companies make and receive different impacts from other companies in different periods. If one can understand what types of network changes affect a company's value, then one would be able to predict the future value of the company, grasp industry innovations, and make business more successful. However, it is often difficult to collect continuous records of network changes, and the models of mining longitudinal network are complicated. In this study, we developed algorithms and a system to infer large-scale evolutionary company networks from public news during 1981--2009. Then, based on how networks change over time, and on the financial information of the companies, we predicted company profit and revenue growth. Herein, we propose a feature extraction and selection algorithm for longitudinal networks. This paper is the first to describe a study examining longitudinal network-mining-based company performance analysis. We measured how networks affect company performance and what network features are important.},
issn={1869-5469},
doi={10.1007/s13278-011-0045-5},
url={https://doi.org/10.1007/s13278-011-0045-5}
}

@inproceedings{ronningstad-etal-2022-entity,
    title = "Entity-Level Sentiment Analysis ({ELSA}): An Exploratory Task Survey",
    author = "R{\o}nningstad, Egil  and
      Velldal, Erik  and
      {\O}vrelid, Lilja",
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.589",
    pages = "6773--6783",
    abstract = "This paper explores the task of identifying the overall sentiment expressed towards volitional entities (persons and organizations) in a document - what we refer to as Entity-Level Sentiment Analysis (ELSA). While identifying sentiment conveyed towards an entity is well researched for shorter texts like tweets, we find little to no research on this specific task for longer texts with multiple mentions and opinions towards the same entity. This lack of research would be understandable if ELSA can be derived from existing tasks and models. To assess this, we annotate a set of professional reviews for their overall sentiment towards each volitional entity in the text. We sample from data already annotated for document-level, sentence-level, and target-level sentiment in a multi-domain review corpus, and our results indicate that there is no single proxy task that provides this overall sentiment we seek for the entities at a satisfactory level of performance. We present a suite of experiments aiming to assess the contribution towards ELSA provided by document-, sentence-, and target-level sentiment analysis, and provide a discussion of their shortcomings. We show that sentiment in our dataset is expressed not only with an entity mention as target, but also towards targets with a sentiment-relevant relation to a volitional entity. In our data, these relations extend beyond anaphoric coreference resolution, and our findings call for further research of the topic. Finally, we also present a survey of previous relevant work.",
}

@article{khedr2017predicting,
  title={Predicting stock market behavior using data mining technique and news sentiment analysis},
  author={Khedr, Ayman E and Yaseen, Nagwa and others},
  journal={International Journal of Intelligent Systems and Applications},
  volume={9},
  number={7},
  pages={22},
  year={2017},
  publisher={Modern Education and Computer Science Press}
}

@article{li2014newsimpact,
title = {News impact on stock price return via sentiment analysis},
journal = {Knowledge-Based Systems},
volume = {69},
pages = {14-23},
year = {2014},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2014.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0950705114001440},
author = {Xiaodong Li and Haoran Xie and Li Chen and Jianping Wang and Xiaotie Deng},
keywords = {News impact, Stock price return, Sentiment, Prediction, Experiment},
abstract = {Financial news articles are believed to have impacts on stock price return. Previous works model news pieces in bag-of-words space, which analyzes the latent relationship between word statistical patterns and stock price movements. However, news sentiment, which is an important ring on the chain of mapping from the word patterns to the price movements, is rarely touched. In this paper, we first implement a generic stock price prediction framework, and plug in six different models with different analyzing approaches. To take one step further, we use Harvard psychological dictionary and Loughran–McDonald financial sentiment dictionary to construct a sentiment space. Textual news articles are then quantitatively measured and projected onto the sentiment space. Instance labeling method is rigorously discussed and tested. We evaluate the models’ prediction accuracy and empirically compare their performance at different market classification levels. Experiments are conducted on five years historical Hong Kong Stock Exchange prices and news articles. Results show that (1) at individual stock, sector and index levels, the models with sentiment analysis outperform the bag-of-words model in both validation set and independent testing set; (2) the models which use sentiment polarity cannot provide useful predictions; (3) there is a minor difference between the models using two different sentiment dictionaries.}
}

@Article{Wan2021,
author={Wan, Xingchen
and Yang, Jie
and Marinov, Slavi
and Calliess, Jan-Peter
and Zohren, Stefan
and Dong, Xiaowen},
title={Sentiment correlation in financial news networks and associated market movements},
journal={Scientific Reports},
year={2021},
month={2},
day={04},
volume={11},
number={1},
pages={3062},
abstract={In an increasingly connected global market, news sentiment towards one company may not only indicate its own market performance, but can also be associated with a broader movement on the sentiment and performance of other companies from the same or even different sectors. In this paper, we apply NLP techniques to understand news sentiment of 87 companies among the most reported on Reuters for a period of 7 years. We investigate the propagation of such sentiment in company networks and evaluate the associated market movements in terms of stock price and volatility. Our results suggest that, in certain sectors, strong media sentiment towards one company may indicate a significant change in media sentiment towards related companies measured as neighbours in a financial network constructed from news co-occurrence. Furthermore, there exists a weak but statistically significant association between strong media sentiment and abnormal market return as well as volatility. Such an association is more significant at the level of individual companies, but nevertheless remains visible at the level of sectors or groups of companies.},
issn={2045-2322},
doi={10.1038/s41598-021-82338-6},
url={https://doi.org/10.1038/s41598-021-82338-6}
}

@INPROCEEDINGS{zhao2021bert,
  author={Zhao, Lingyun and Li, Lin and Zheng, Xinhao and Zhang, Jianwei},
  booktitle={2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={A BERT based Sentiment Analysis and Key Entity Detection Approach for Online Financial Texts}, 
  year={2021},
  volume={},
  number={},
  pages={1233-1238},
  keywords={Text mining;Support vector machines;Sentiment analysis;Analytical models;Social networking (online);Conferences;Bit error rate;online financial text mining;sentiment analysis;key entity detection;BERT},
  doi={10.1109/CSCWD49262.2021.9437616}}


@misc{liu2019roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{liu2019mrc,
AUTHOR = {Liu, Shanshan and Zhang, Xin and Zhang, Sheng and Wang, Hui and Zhang, Weiming},
TITLE = {Neural Machine Reading Comprehension: Methods and Trends},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {3698},
URL = {https://www.mdpi.com/2076-3417/9/18/3698},
ISSN = {2076-3417},
ABSTRACT = {Machine reading comprehension (MRC), which requires a machine to answer questions based on a given context, has attracted increasing attention with the incorporation of various deep-learning techniques over the past few years. Although research on MRC based on deep learning is flourishing, there remains a lack of a comprehensive survey summarizing existing approaches and recent trends, which motivated the work presented in this article. Specifically, we give a thorough review of this research field, covering different aspects including (1) typical MRC tasks: their definitions, differences, and representative datasets; (2) the general architecture of neural MRC: the main modules and prevalent approaches to each; and (3) new trends: some emerging areas in neural MRC as well as the corresponding challenges. Finally, considering what has been achieved so far, the survey also envisages what the future may hold by discussing the open issues left to be addressed.},
DOI = {10.3390/app9183698}
}

@article{reuters2022,
  title={After crypto, Stocktwits takes aim at stocks trading},
  author={Medha Singh},
  journal={Reuters},
  publisher={Reuters},
  month={7},
  year={2022},
  url={https://www.reuters.com/technology/after-crypto-stocktwits-takes-aim-stocks-trading-2022-07-19/},
  urldate = {2023-12-20}
}

@misc{keraghel2024survey,
      title={A survey on recent advances in named entity recognition}, 
      author={Imed Keraghel and Stanislas Morbieu and Mohamed Nadif},
      year={2024},
      eprint={2401.10825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{ramshaw-marcus-1995-text,
    title = "Text Chunking using Transformation-Based Learning",
    author = "Ramshaw, Lance  and
      Marcus, Mitch",
    booktitle = "Third Workshop on Very Large Corpora",
    year = "1995",
    url = "https://aclanthology.org/W95-0107",
}

@book{wang2005svm,
  title={Support vector machines: theory and applications},
  author={Wang, Lipo},
  volume={177},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@article{sutton2012crf,
  title={An introduction to conditional random fields},
  author={Sutton, Charles and McCallum, Andrew and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={4},
  pages={267--373},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{berger1996me,
  title={A maximum entropy approach to natural language processing},
  author={Berger, Adam and Della Pietra, Stephen A and Della Pietra, Vincent J},
  journal={Computational linguistics},
  volume={22},
  number={1},
  pages={39--71},
  year={1996}
}

@article{EDDY1996361hmm,
title = {Hidden Markov models},
journal = {Current Opinion in Structural Biology},
volume = {6},
number = {3},
pages = {361-365},
year = {1996},
issn = {0959-440X},
doi = {https://doi.org/10.1016/S0959-440X(96)80056-X},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X9680056X},
author = {Sean R Eddy},
abstract = {‘Profiles’ of protein structures and sequence alignments can detect subtle homologies. Profile analysis has been put on firmer mathematical ground by the introduction of hidden Markov model (HMM) methods. During the past year, applications of these powerful new HMM-based profiles have begun to appear in the fields of protein-structure prediction and large-scale genome-sequence analysis.}
}

@ARTICLE{9072123kmeans,
  author={Sinaga, Kristina P. and Yang, Miin-Shen},
  journal={IEEE Access}, 
  title={Unsupervised K-Means Clustering Algorithm}, 
  year={2020},
  volume={8},
  number={},
  pages={80716-80727},
  keywords={Clustering algorithms;Indexes;Linear programming;Entropy;Clustering methods;Unsupervised learning;Machine learning algorithms;Clustering;K-means;number of clusters;initializations;unsupervised learning schema;Unsupervised k-means (U-k-means)},
  doi={10.1109/ACCESS.2020.2988796}}

@article{AIZAWA200345tfidf,
title = {An information-theoretic perspective of tf–idf measures},
journal = {Information Processing \& Management},
volume = {39},
number = {1},
pages = {45-65},
year = {2003},
issn = {0306-4573},
doi = {https://doi.org/10.1016/S0306-4573(02)00021-3},
url = {https://www.sciencedirect.com/science/article/pii/S0306457302000213},
author = {Akiko Aizawa},
keywords = {tf–idf, Term weighting theories, Information theory, Text categorization},
abstract = {This paper presents a mathematical definition of the “probability-weighted amount of information” (PWI), a measure of specificity of terms in documents that is based on an information-theoretic view of retrieval events. The proposed PWI is expressed as a product of the occurrence probabilities of terms and their amounts of information, and corresponds well with the conventional term frequency–inverse document frequency measures that are commonly used in today’s information retrieval systems. The mathematical definition of the PWI is shown, together with some illustrative examples of the calculation.}
}

@article{mikolov2013word2vec,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@misc{joulin2016bagfasttext,
      title={Bag of Tricks for Efficient Text Classification}, 
      author={Armand Joulin and Edouard Grave and Piotr Bojanowski and Tomas Mikolov},
      year={2016},
      eprint={1607.01759},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{pennington-etal-2014-glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@misc{peters2018elmo,
      title={Deep contextualized word representations}, 
      author={Matthew E. Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer},
      year={2018},
      eprint={1802.05365},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@online{ibm_neural_networks,
  author = {IBM},
  title = {Neural Networks},
  year = {2024},
  url = {https://www.ibm.com/topics/neural-networks},
  urldate = {2024-03-08}
}

@online{ibm_ai_ml_dl_nn,
  author = {IBM},
  title = {AI vs. Machine Learning vs. Deep Learning vs. Neural Networks},
  year = {2024},
  url = {https://www.ibm.com/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks/},
  urldate = {2024-03-08}
}

@inproceedings{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I and others},
  booktitle={Soviet physics doklady},
  volume={10},
  number={8},
  pages={707--710},
  year={1966},
  organization={Soviet Union}
}


# ZKONTROLOVAT
@misc{spacy_kb,
  author       = {spaCy},
  title        = {KnowledgeBase · spaCy API Documentation},
  year         = {2024},
  url          = {https://spacy.io/api/kb},
  urldate      = {2024-06-09}
}

# ZKONTROLOVAT
@misc{wikidata_glossary,
  author = {Wikidata},
	title = {{Wikidata:Glossary - Wikidata}},
  year = {2024},
	url = {https://www.wikidata.org/wiki/Wikidata:Glossary},
  urldate      = {2024-06-09}
}

# FinBERT
@misc{araci2019finbert,
      title={FinBERT: Financial Sentiment Analysis with Pre-trained Language Models}, 
      author={Dogu Araci},
      year={2019},
      eprint={1908.10063},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

# FinEntity
@inproceedings{tang-etal-2023-finentity,
    title = "{F}in{E}ntity: Entity-level Sentiment Classification for Financial Texts",
    author = "Tang, Yixuan  and
      Yang, Yi  and
      Huang, Allen  and
      Tam, Andy  and
      Tang, Justin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.956",
    doi = "10.18653/v1/2023.emnlp-main.956",
    pages = "15465--15471",
    abstract = "In the financial domain, conducting entity-level sentiment analysis is crucial for accurately assessing the sentiment directed toward a specific financial entity. To our knowledge, no publicly available dataset currently exists for this purpose. In this work, we introduce an entity-level sentiment classification dataset, called FinEntity, that annotates financial entity spans and their sentiment (positive, neutral, and negative) in financial news. We document the dataset construction process in the paper. Additionally, we benchmark several pre-trained models (BERT, FinBERT, etc.) and ChatGPT on entity-level sentiment classification. In a case study, we demonstrate the practical utility of using FinEntity in monitoring cryptocurrency markets. The data and code of FinEntity is available at https://github.com/yixuantt/FinEntity.",
}


#T5
@article{t5Colin,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

#Sentfin
@article{sentfin,
author = {Sinha, Ankur and Kedas, Satishwar and Kumar, Rishu and Malo, Pekka},
title = {SEntFiN 1.0: Entity-aware sentiment analysis for financial news},
journal = {Journal of the Association for Information Science and Technology},
volume = {73},
number = {9},
pages = {1314-1335},
doi = {https://doi.org/10.1002/asi.24634},
url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.24634},
eprint = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24634},
abstract = {Abstract Fine-grained financial sentiment analysis on news headlines is a challenging task requiring human-annotated datasets to achieve high performance. Limited studies have tried to address the sentiment extraction task in a setting where multiple entities are present in a news headline. In an effort to further research in this area, we make publicly available SEntFiN 1.0, a human-annotated dataset of 10,753 news headlines with entity-sentiment annotations, of which 2,847 headlines contain multiple entities, often with conflicting sentiments. We augment our dataset with a database of over 1,000 financial entities and their various representations in news media amounting to over 5,000 phrases. We propose a framework that enables the extraction of entity-relevant sentiments using a feature-based approach rather than an expression-based approach. For sentiment extraction, we utilize 12 different learning schemes utilizing lexicon-based and pretrained sentence representations and five classification approaches. Our experiments indicate that lexicon-based N-gram ensembles are above par with pretrained word embedding schemes such as GloVe. Overall, RoBERTa and finBERT (domain-specific BERT) achieve the highest average accuracy of 94.29\% and F1-score of 93.27\%. Further, using over 210,000 entity-sentiment predictions, we validate the economic effect of sentiments on aggregate market movements over a long duration.},
year = {2022}
}

@article{FinABSAArticle,
  title={Removing non-stationary knowledge from pre-trained language models for entity-level sentiment classification in finance},
  author={Son, Guijin and Lee, Hanwool and Kang, Nahyeon and Hahm, Moonjeong},
  journal={arXiv preprint arXiv:2301.03136},
  year={2023}
}

# TODO: Delete?
@online{name_matcher_lib,
  author = {De Nederlandsche Bank},
  title = {Name Matching},
  year = {2024},
  url = {https://github.com/DeNederlandscheBank/name_matching/},
  urldate = {2024-05-09}
}

@misc{adj_close_bib,
  title = {Understanding equities data},
  booktitle = {Quantstart.com},
  author = {Quantstart},
  year = {2024},
  url = {https://quantstart.com/articles/understanding-equities-data/},
  urldate = {2024-05-15}
}

# Zkontrolovat
@MISC{laura2023-medium,
  title = {Using Airflow {XComs} - Laura},
  booktitle = {Medium},
  author = {Laura},
  year = {2023},
  month = {3},
  url = {https://medium.com/@laura-fyi/using-airflow-xcoms-4703ea5e534a},
  urldate = {2024-05-12}
}

# Zkontrolovat
@MISC{Stempel2023,
  title = {{NY} Times sues {OpenAI}, Microsoft for infringing copyrighted works},
  booktitle = {Reuters.com},
  author = {Stempel, Jonathan},
  year  =  {2023},
  month =  {12},
  url = {https://www.reuters.com/legal/transactional/ny-times-sues-openai-microsoft-infringing-copyrighted-work-2023-12-27/},
  urldate = {2024-5-15}
}

@MISC{Bergen2023,
  title = {New York Times Sues Microsoft and {OpenAI} for Copyright Infringement},
  booktitle = {Bloomberg.com},
  author = {Bergen, Mark},
  year = 2023,
  month =  {12},
  url = {https://www.bloomberg.com/news/articles/2023-12-27/new-york-times-sues-microsoft-and-openai-for-copyright-infringement},
  urldate = {2024-5-15}
}

@MISC{Robertson2024,
  title = {8 Daily Newspapers Sue {OpenAI} and Microsoft Over {A.I}},
  booktitle = {Nytimes.com},
  author = {Robertson, Katie},
  year = {2024},
  month = {4},
  url = {https://www.nytimes.com/2024/04/30/business/media/newspapers-sued-microsoft-openai.html},
  urldate = {2024-5-15}
}

@ARTICLE{Associated_Press2024,
  title = {Eight {US} newspapers sue {OpenAI} and Microsoft for copyright infringement},
  author = {Guardian, The},
  journal = {Guardian},
  publisher = {The Guardian},
  month = {4},
  year = {2024},
  urldate = {2024-5-15}
}

@MISC{finnhub_doc,
  title = {Finnhub - Free realtime {APIs} for stock, forex and cryptocurrency},
  booktitle = {Finnhub.io},
  author = {Finnhub},
  url = {https://finnhub.io/docs/api/company-news},
  urldate = {2024-5-16},
}

@MISC{atom-wiki,
  title        = "Difference Between {RSS} and {ATOM}",
  booktitle    = "Tutorialspoint.com",
  author       = "Sajid, Md",
  year         = {2023},
  month        = {7},
  url = {https://www.tutorialspoint.com/difference-between-rss-and-atom},
  urldate      = {2024-7-15},
}

@MISC{rssmarco,
  title        = "How do {RSS} feeds work?",
  booktitle    = "{RSS.com} Blog - Podcasting and Beyond",
  author       = "{Marc}",
  publisher    = "RSS.com",
  month        =  {2},
  year         =  {2024},
  url = {https://rss.com/blog/how-do-rss-feeds-work/},
  urldate      = {2024-7-15}
}


















@book{knuth1979tex,
  title={TEX and METAFONT: New directions in typesetting},
  author={Knuth, Donald Ervin},
  year={1979},
  publisher={American Mathematical Society}
}

@book{lamport1994latex,
  title={LATEX: a document preparation system: user's guide and reference manual},
  author={Lamport, Leslie},
  year={1994},
  publisher={Addison-Wesley}
}

@book{glasman2010science,
  title={Science research writing for non-native speakers of English},
  author={Glasman-Deal, Hilary},
  year={2010},
  publisher={World Scientific}
}

@book{sparling1989english,
  title={English or Czenglish? Jak se vyhnout čechismům v angličtině},
  author={Sparling, Don},
  year={1989},
  publisher={Státní pedagogické nakladatelství}
}

@book{tufte1990envisioning,
  title={Envisioning information},
  author={Tufte, Edward R and Goeler, Nora Hillman and Benson, Richard},
  year={1990},
  publisher={Graphics press Cheshire, CT}
}

@book{tufte1983visual,
  title={Visual display of quantitative information},
  author={Tufte, Edward R},
  year={1983},
  publisher={Graphics press Cheshire, CT}
}

@book{wilke2019fundamentals,
  title={Fundamentals of Data Visualization},
  author={Wilke, Claus O},
  year={2019},
  publisher={O'Reilly Media, Inc.},
  url={https://clauswilke.com/dataviz/},
  isbn={9781492031086}
}

@techreport{tantau2015tikz,
  title={The TikZ and PGF Packages (Manual for version 3.1.8b)},
  author={Tantau, Till},
  year={2020},
  institution={Institut f{\"u}r Theoretische Informatik Universit{\"a}t zu L{\"u}beck},
  url={http://mirrors.ctan.org/graphics/pgf/base/doc/pgfmanual.pdf}
}
